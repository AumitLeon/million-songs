{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Neural Net Sequential Model\n",
    "In order to test an algorithm capable of GPU/CPU support and deep learning models, we've begun exploring building a neural net with the Keras library. This notebook will catalog these experiements. The following code uses the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils, generic_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start building the network. Currently 5 hidden layers, with 100 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=90))\n",
    "model.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(units=2011, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters: Using categorical_crossentropy and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data: initial split is as follows--10,000 training exampes and 1,000 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING DATASET\n",
      "\n",
      "SPLITTING TRAINING AND TEST SETS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype |S12 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "examples = []\n",
    "print \"GETTING DATASET\"\n",
    "print\n",
    "# Replace filename with the path to the CSV where you have the year predictions data saved.\n",
    "filename = \"/mnt/c/Users/Aumit/Desktop/YearPredictionMSD.txt/yp.csv\"\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        content = line.split(\",\")\n",
    "        \n",
    "        labels.append(content[0])\n",
    "\n",
    "        content.pop(0)\n",
    "\n",
    "        # If we wanted pure lists\n",
    "        #content = [float(elem) for elem in content]\n",
    "        #content = map(float, content)\n",
    "\n",
    "        # If we want a list of numpy arrays, not necessary\n",
    "        #npa = np.asarray(content, dtype=np.float64)\n",
    "\n",
    "        examples.append(content)\n",
    "\n",
    "print \"SPLITTING TRAINING AND TEST SETS\"\n",
    "print \n",
    "# Turning lists into numpy arrays\n",
    "total_array = np.array(examples)\n",
    "\n",
    "# Scale the features so they have 0 mean\n",
    "total_scaled = preprocessing.scale(total_array)\n",
    "\n",
    "# Numpy array of the labels \n",
    "total_labels = np.array(labels)\n",
    "# \n",
    "# Split training and test:\n",
    "# Increase or decrease these sizes\n",
    "# Currently using first 10000 examples as training data\n",
    "# Last 1000 as test data\n",
    "training_examples = total_scaled[:10000]\n",
    "#training_examples = random.sample(total_array, 10)\n",
    "training_labels = total_labels[:10000]\n",
    "\n",
    "# Use the following 1000 examples as text examples\n",
    "test_examples = total_scaled[10000:11000]\n",
    "test_labels = total_labels[10000:11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our labels to work with keras, we need to conver them via the to_categorical function. As of right now, we have 2011 classes (years 0 -> 2011). This means our label vectors have a lot of 0's for all the years it doesn't have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(training_labels, num_classes=2011)\n",
    "\n",
    "y_test = keras.utils.to_categorical(test_labels, num_classes=2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 5.6850 - acc: 0.0629\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 3.5141 - acc: 0.0675\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 3.4368 - acc: 0.0733\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 3.4071 - acc: 0.0707\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 3.3789 - acc: 0.0731\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 3.3592 - acc: 0.0776\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 3.3424 - acc: 0.0775\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 3.3223 - acc: 0.0749\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 3.2979 - acc: 0.0851\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 3.2699 - acc: 0.0925\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 3.2480 - acc: 0.0986\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 3.2189 - acc: 0.0978\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 3.1955 - acc: 0.0979\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 3.1706 - acc: 0.1018\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 3.1490 - acc: 0.1080\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 3.1259 - acc: 0.1118\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 3.1087 - acc: 0.1171\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 3.0895 - acc: 0.1185\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 3.0757 - acc: 0.1245\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 3.0582 - acc: 0.1251\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 3.0397 - acc: 0.1310\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 3.0246 - acc: 0.1381\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 3.0057 - acc: 0.1419\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 2.9895 - acc: 0.1455\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 2.9711 - acc: 0.1459\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 2.9545 - acc: 0.1511\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 2.9380 - acc: 0.1508\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 2.9196 - acc: 0.1613\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 2.9022 - acc: 0.1654\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 2.8782 - acc: 0.1773 1s\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 2.8650 - acc: 0.1705\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 2.8454 - acc: 0.1767\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 2.8181 - acc: 0.1782\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 2.8034 - acc: 0.1856\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 2.7805 - acc: 0.1916\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 2.7607 - acc: 0.1980\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 2.7400 - acc: 0.2042\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 2.7163 - acc: 0.2091\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 2.6893 - acc: 0.2221\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 6s 612us/step - loss: 2.6711 - acc: 0.2281\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 6s 598us/step - loss: 2.6503 - acc: 0.2292\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 6s 590us/step - loss: 2.6289 - acc: 0.2344\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 2.6035 - acc: 0.2407\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 2.5840 - acc: 0.2464\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 2.5580 - acc: 0.2633\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 2.5361 - acc: 0.2648\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 2.5168 - acc: 0.2651\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 2.4934 - acc: 0.2738\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 2.4694 - acc: 0.2788\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 2.4475 - acc: 0.2859\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 2.4253 - acc: 0.2894\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 2.3955 - acc: 0.2945\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 2.3786 - acc: 0.3075\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 2.3571 - acc: 0.3115\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 2.3323 - acc: 0.3181\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 2.3072 - acc: 0.3245\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 2.2828 - acc: 0.3293\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 2.2629 - acc: 0.3386\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 2.2415 - acc: 0.3421\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 2.2192 - acc: 0.3458\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 2.1980 - acc: 0.3519\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 2.1765 - acc: 0.3595\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 6s 598us/step - loss: 2.1448 - acc: 0.3631\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 2.1239 - acc: 0.3699\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 2.1132 - acc: 0.3762\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 2.0854 - acc: 0.3792\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 2.0572 - acc: 0.3911\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 2.0397 - acc: 0.3952\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 2.0204 - acc: 0.4000\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 1.9920 - acc: 0.4050\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 1.9803 - acc: 0.4119\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 1.9515 - acc: 0.4181\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 1.9191 - acc: 0.4281\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 1.9006 - acc: 0.4355\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 1.8715 - acc: 0.4438\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 6s 622us/step - loss: 1.8596 - acc: 0.4444\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 1.8380 - acc: 0.4511\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 1.8347 - acc: 0.4509\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 1.7908 - acc: 0.4628\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.7629 - acc: 0.4732\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 1.7501 - acc: 0.4779\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.7361 - acc: 0.4804\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 1.6940 - acc: 0.4957\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 1.6787 - acc: 0.4974\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 1.6513 - acc: 0.5082\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 1.6497 - acc: 0.5032\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 1.6235 - acc: 0.5170\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 1.5861 - acc: 0.5255\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 1.5835 - acc: 0.5247\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 1.5414 - acc: 0.5393\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.5168 - acc: 0.5492\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.4951 - acc: 0.5509\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.4779 - acc: 0.5550\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.4598 - acc: 0.5568\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 1.4501 - acc: 0.5672\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 1.4315 - acc: 0.5716\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 1.4140 - acc: 0.5775\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 1.3833 - acc: 0.5844\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 5s 466us/step - loss: 1.3492 - acc: 0.5906\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 1.3515 - acc: 0.5927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b2c1205d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_examples, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the sake of time, we only did 100 epochs so training accuracy only reached 59%, but with 200 epochs (and the same number of training exmaples) we reach 99.99% training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 168us/step\n",
      "[1.1825393805980682, 0.65100000000000002]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(training_examples, y_train, batch_size=32)\n",
    "print loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We have confirmed that the model is able to overfit (we weren't able to achieve this result with scikit-learn. Our next steps should focus on how to address overfitting, i.e, looking at regularization and adding more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_examples = total_scaled[:30000]\n",
    "#training_examples = random.sample(total_array, 10)\n",
    "training_labels = total_labels[:30000]\n",
    "\n",
    "test_examples = total_scaled[30000:31000]\n",
    "test_labels = total_labels[30000:31000]\n",
    "\n",
    "y_train = keras.utils.to_categorical(training_labels, num_classes=2011)\n",
    "\n",
    "y_test = keras.utils.to_categorical(test_labels, num_classes=2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our new network architecture: 4 hidden units, and lambda = 0.000001 in each hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(units=100, activation='relu', input_dim=90))\n",
    "model_1.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=50, activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "model_1.add(Dense(units=50, activation='relu'))\n",
    "#model.add(Flatten())\n",
    "model_1.add(Dense(units=2011, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 5.2672 - acc: 0.0656\n",
      "Epoch 2/200\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 3.4808 - acc: 0.0680\n",
      "Epoch 3/200\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 3.4410 - acc: 0.0683\n",
      "Epoch 4/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 3.4181 - acc: 0.0687\n",
      "Epoch 5/200\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 3.3984 - acc: 0.0720\n",
      "Epoch 6/200\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 3.3814 - acc: 0.0722\n",
      "Epoch 7/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 3.3632 - acc: 0.0704\n",
      "Epoch 8/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 3.3343 - acc: 0.0742\n",
      "Epoch 9/200\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 3.2974 - acc: 0.0791\n",
      "Epoch 10/200\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 3.2666 - acc: 0.0791\n",
      "Epoch 11/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 3.2429 - acc: 0.0839\n",
      "Epoch 12/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 3.2266 - acc: 0.0856\n",
      "Epoch 13/200\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 3.2143 - acc: 0.0836\n",
      "Epoch 14/200\n",
      "30000/30000 [==============================] - 14s 451us/step - loss: 3.2010 - acc: 0.0886\n",
      "Epoch 15/200\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 3.1893 - acc: 0.0910\n",
      "Epoch 16/200\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 3.1791 - acc: 0.0894\n",
      "Epoch 17/200\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 3.1683 - acc: 0.0934\n",
      "Epoch 18/200\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 3.1578 - acc: 0.0931\n",
      "Epoch 19/200\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 3.1475 - acc: 0.0940\n",
      "Epoch 20/200\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 3.1363 - acc: 0.0964\n",
      "Epoch 21/200\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 3.1247 - acc: 0.0950\n",
      "Epoch 22/200\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 3.1123 - acc: 0.0956\n",
      "Epoch 23/200\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 3.1008 - acc: 0.0994\n",
      "Epoch 24/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 3.0866 - acc: 0.1029\n",
      "Epoch 25/200\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 3.0753 - acc: 0.1032\n",
      "Epoch 26/200\n",
      "30000/30000 [==============================] - 14s 468us/step - loss: 3.0621 - acc: 0.1029\n",
      "Epoch 27/200\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 3.0478 - acc: 0.1074\n",
      "Epoch 28/200\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 3.0350 - acc: 0.1105\n",
      "Epoch 29/200\n",
      "30000/30000 [==============================] - 17s 568us/step - loss: 3.0201 - acc: 0.1117\n",
      "Epoch 30/200\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 3.0097 - acc: 0.1115\n",
      "Epoch 31/200\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 2.9930 - acc: 0.1148\n",
      "Epoch 32/200\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 2.9801 - acc: 0.1159\n",
      "Epoch 33/200\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 2.9646 - acc: 0.1172\n",
      "Epoch 34/200\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 2.9513 - acc: 0.1216\n",
      "Epoch 35/200\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 2.9380 - acc: 0.1240\n",
      "Epoch 36/200\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 2.9265 - acc: 0.1246\n",
      "Epoch 37/200\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 2.9105 - acc: 0.1270\n",
      "Epoch 38/200\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 2.8976 - acc: 0.1293\n",
      "Epoch 39/200\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 2.8859 - acc: 0.1329\n",
      "Epoch 40/200\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 2.8723 - acc: 0.1334\n",
      "Epoch 41/200\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 2.8614 - acc: 0.1351\n",
      "Epoch 42/200\n",
      "30000/30000 [==============================] - 18s 596us/step - loss: 2.8454 - acc: 0.1357\n",
      "Epoch 43/200\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 2.8332 - acc: 0.1428\n",
      "Epoch 44/200\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 2.8193 - acc: 0.1398\n",
      "Epoch 45/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 2.8049 - acc: 0.1455\n",
      "Epoch 46/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 2.7947 - acc: 0.1438\n",
      "Epoch 47/200\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 2.7833 - acc: 0.1486\n",
      "Epoch 48/200\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 2.7686 - acc: 0.1520\n",
      "Epoch 49/200\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 2.7563 - acc: 0.1547\n",
      "Epoch 50/200\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 2.7466 - acc: 0.1507\n",
      "Epoch 51/200\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 2.7301 - acc: 0.1597\n",
      "Epoch 52/200\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 2.7207 - acc: 0.1618\n",
      "Epoch 53/200\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 2.7089 - acc: 0.1608\n",
      "Epoch 54/200\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 2.6970 - acc: 0.1614\n",
      "Epoch 55/200\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 2.6819 - acc: 0.1653\n",
      "Epoch 56/200\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 2.6698 - acc: 0.1698\n",
      "Epoch 57/200\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 2.6567 - acc: 0.1715\n",
      "Epoch 58/200\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 2.6466 - acc: 0.1737\n",
      "Epoch 59/200\n",
      "30000/30000 [==============================] - 17s 568us/step - loss: 2.6321 - acc: 0.1773\n",
      "Epoch 60/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 2.6212 - acc: 0.1764\n",
      "Epoch 61/200\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 2.6113 - acc: 0.1809\n",
      "Epoch 62/200\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 2.5974 - acc: 0.1834\n",
      "Epoch 63/200\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 2.5863 - acc: 0.1898\n",
      "Epoch 64/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 2.5744 - acc: 0.1891\n",
      "Epoch 65/200\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 2.5620 - acc: 0.1927\n",
      "Epoch 66/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 2.5544 - acc: 0.1947\n",
      "Epoch 67/200\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 2.5447 - acc: 0.1981\n",
      "Epoch 68/200\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 2.5278 - acc: 0.2002\n",
      "Epoch 69/200\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 2.5160 - acc: 0.2045\n",
      "Epoch 70/200\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 2.5106 - acc: 0.2050\n",
      "Epoch 71/200\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 2.4937 - acc: 0.2086\n",
      "Epoch 72/200\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 2.4872 - acc: 0.2119\n",
      "Epoch 73/200\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 2.4739 - acc: 0.2156\n",
      "Epoch 74/200\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 2.4578 - acc: 0.2146\n",
      "Epoch 75/200\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 2.4549 - acc: 0.2203\n",
      "Epoch 76/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 2.4363 - acc: 0.2206\n",
      "Epoch 77/200\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 2.4226 - acc: 0.2229\n",
      "Epoch 78/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 2.4185 - acc: 0.2251\n",
      "Epoch 79/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 2.4005 - acc: 0.2315\n",
      "Epoch 80/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 2.3931 - acc: 0.2323\n",
      "Epoch 81/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 2.3814 - acc: 0.2340\n",
      "Epoch 82/200\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 2.3719 - acc: 0.2366\n",
      "Epoch 83/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 2.3615 - acc: 0.2393\n",
      "Epoch 84/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 2.3509 - acc: 0.2445\n",
      "Epoch 85/200\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 2.3393 - acc: 0.2467\n",
      "Epoch 86/200\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 2.3224 - acc: 0.2530\n",
      "Epoch 87/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 2.3157 - acc: 0.2526\n",
      "Epoch 88/200\n",
      "30000/30000 [==============================] - 13s 439us/step - loss: 2.3043 - acc: 0.2553\n",
      "Epoch 89/200\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 2.2866 - acc: 0.2640\n",
      "Epoch 90/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 2.2883 - acc: 0.2575\n",
      "Epoch 91/200\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 2.2773 - acc: 0.2627\n",
      "Epoch 92/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 2.2597 - acc: 0.2710\n",
      "Epoch 93/200\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 2.2608 - acc: 0.2680\n",
      "Epoch 94/200\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 2.2360 - acc: 0.2766\n",
      "Epoch 95/200\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 2.2334 - acc: 0.2735\n",
      "Epoch 96/200\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 2.2198 - acc: 0.2823\n",
      "Epoch 97/200\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 2.2058 - acc: 0.2855\n",
      "Epoch 98/200\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 2.1974 - acc: 0.2860\n",
      "Epoch 99/200\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 2.1838 - acc: 0.2894\n",
      "Epoch 100/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 2.1869 - acc: 0.2887\n",
      "Epoch 101/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 2.1745 - acc: 0.2973\n",
      "Epoch 102/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 2.1488 - acc: 0.3003\n",
      "Epoch 103/200\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 2.1415 - acc: 0.3018\n",
      "Epoch 104/200\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 2.1364 - acc: 0.3040\n",
      "Epoch 105/200\n",
      "30000/30000 [==============================] - 19s 629us/step - loss: 2.1291 - acc: 0.3042\n",
      "Epoch 106/200\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 2.1224 - acc: 0.3112\n",
      "Epoch 107/200\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 2.1098 - acc: 0.3147\n",
      "Epoch 108/200\n",
      "30000/30000 [==============================] - 13s 450us/step - loss: 2.0896 - acc: 0.3195\n",
      "Epoch 109/200\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 2.0728 - acc: 0.3270\n",
      "Epoch 110/200\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 2.0729 - acc: 0.3213\n",
      "Epoch 111/200\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 2.0602 - acc: 0.3313\n",
      "Epoch 112/200\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 2.0476 - acc: 0.3334\n",
      "Epoch 113/200\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 2.0371 - acc: 0.3327\n",
      "Epoch 114/200\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 2.0272 - acc: 0.3412\n",
      "Epoch 115/200\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 2.0121 - acc: 0.3442\n",
      "Epoch 116/200\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 2.0042 - acc: 0.3464\n",
      "Epoch 117/200\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 2.0038 - acc: 0.3501\n",
      "Epoch 118/200\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 1.9814 - acc: 0.3557\n",
      "Epoch 119/200\n",
      "30000/30000 [==============================] - 14s 480us/step - loss: 1.9815 - acc: 0.3568\n",
      "Epoch 120/200\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 1.9720 - acc: 0.3594\n",
      "Epoch 121/200\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 1.9572 - acc: 0.3622\n",
      "Epoch 122/200\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 1.9359 - acc: 0.3719\n",
      "Epoch 123/200\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 1.9294 - acc: 0.3692\n",
      "Epoch 124/200\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 1.9251 - acc: 0.3750\n",
      "Epoch 125/200\n",
      "30000/30000 [==============================] - 14s 470us/step - loss: 1.9204 - acc: 0.3779\n",
      "Epoch 126/200\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 1.8950 - acc: 0.3802\n",
      "Epoch 127/200\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 1.8840 - acc: 0.3850\n",
      "Epoch 128/200\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 1.8871 - acc: 0.3871\n",
      "Epoch 129/200\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 1.8737 - acc: 0.3887\n",
      "Epoch 130/200\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 1.8645 - acc: 0.3925\n",
      "Epoch 131/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 1.8488 - acc: 0.3973\n",
      "Epoch 132/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 1.8429 - acc: 0.3987\n",
      "Epoch 133/200\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 1.8309 - acc: 0.4039\n",
      "Epoch 134/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 1.8157 - acc: 0.4096\n",
      "Epoch 135/200\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 1.8215 - acc: 0.4105\n",
      "Epoch 136/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 1.8190 - acc: 0.4094\n",
      "Epoch 137/200\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 1.7969 - acc: 0.4149\n",
      "Epoch 138/200\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 1.7838 - acc: 0.4200\n",
      "Epoch 139/200\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 1.7839 - acc: 0.4203\n",
      "Epoch 140/200\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 1.7613 - acc: 0.4256\n",
      "Epoch 141/200\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 1.7643 - acc: 0.4284\n",
      "Epoch 142/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 1.7376 - acc: 0.4315\n",
      "Epoch 143/200\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 1.7545 - acc: 0.4337\n",
      "Epoch 144/200\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 1.7234 - acc: 0.4415\n",
      "Epoch 145/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 1.7171 - acc: 0.4398\n",
      "Epoch 146/200\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 1.7113 - acc: 0.4417\n",
      "Epoch 147/200\n",
      "30000/30000 [==============================] - 13s 439us/step - loss: 1.7067 - acc: 0.4451\n",
      "Epoch 148/200\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 1.7033 - acc: 0.4466\n",
      "Epoch 149/200\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 1.6872 - acc: 0.4519\n",
      "Epoch 150/200\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 1.6714 - acc: 0.4584\n",
      "Epoch 151/200\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 1.6693 - acc: 0.4566\n",
      "Epoch 152/200\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 1.6676 - acc: 0.4561\n",
      "Epoch 153/200\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 1.6613 - acc: 0.4580\n",
      "Epoch 154/200\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 1.6562 - acc: 0.4579\n",
      "Epoch 155/200\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 1.6395 - acc: 0.4642\n",
      "Epoch 156/200\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 1.6209 - acc: 0.4743\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 14s 478us/step - loss: 1.6084 - acc: 0.4743\n",
      "Epoch 158/200\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 1.6328 - acc: 0.4718\n",
      "Epoch 159/200\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 1.5992 - acc: 0.4803\n",
      "Epoch 160/200\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 1.5946 - acc: 0.4832\n",
      "Epoch 161/200\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 1.5819 - acc: 0.4872\n",
      "Epoch 162/200\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 1.5772 - acc: 0.4878\n",
      "Epoch 163/200\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 1.5802 - acc: 0.4905\n",
      "Epoch 164/200\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 1.5866 - acc: 0.4879\n",
      "Epoch 165/200\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 1.5587 - acc: 0.4939\n",
      "Epoch 166/200\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 1.5496 - acc: 0.4959\n",
      "Epoch 167/200\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 1.5405 - acc: 0.4990\n",
      "Epoch 168/200\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 1.5414 - acc: 0.4991\n",
      "Epoch 169/200\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 1.5124 - acc: 0.5086\n",
      "Epoch 170/200\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 1.5205 - acc: 0.5051\n",
      "Epoch 171/200\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 1.5204 - acc: 0.5083\n",
      "Epoch 172/200\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 1.5207 - acc: 0.5079\n",
      "Epoch 173/200\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 1.5201 - acc: 0.5115\n",
      "Epoch 174/200\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 1.5019 - acc: 0.5139\n",
      "Epoch 175/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 1.4817 - acc: 0.5155\n",
      "Epoch 176/200\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 1.4602 - acc: 0.5268\n",
      "Epoch 177/200\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 1.4546 - acc: 0.5287\n",
      "Epoch 178/200\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 1.4509 - acc: 0.5280\n",
      "Epoch 179/200\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 1.4738 - acc: 0.5241\n",
      "Epoch 180/200\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 1.4723 - acc: 0.5228\n",
      "Epoch 181/200\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 1.4420 - acc: 0.5330\n",
      "Epoch 182/200\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 1.4508 - acc: 0.5326\n",
      "Epoch 183/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 1.4312 - acc: 0.5395\n",
      "Epoch 184/200\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 1.4344 - acc: 0.5356\n",
      "Epoch 185/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 1.4026 - acc: 0.5432\n",
      "Epoch 186/200\n",
      "30000/30000 [==============================] - 14s 467us/step - loss: 1.3999 - acc: 0.5469\n",
      "Epoch 187/200\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 1.4047 - acc: 0.5440\n",
      "Epoch 188/200\n",
      "30000/30000 [==============================] - 14s 476us/step - loss: 1.4252 - acc: 0.5395\n",
      "Epoch 189/200\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 1.3952 - acc: 0.5478\n",
      "Epoch 190/200\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 1.3831 - acc: 0.5550\n",
      "Epoch 191/200\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 1.3782 - acc: 0.5567\n",
      "Epoch 192/200\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 1.3711 - acc: 0.5580\n",
      "Epoch 193/200\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 1.3864 - acc: 0.5515\n",
      "Epoch 194/200\n",
      "30000/30000 [==============================] - 14s 470us/step - loss: 1.4128 - acc: 0.5454\n",
      "Epoch 195/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 1.3578 - acc: 0.5623\n",
      "Epoch 196/200\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 1.3666 - acc: 0.5606\n",
      "Epoch 197/200\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 1.3601 - acc: 0.5595\n",
      "Epoch 198/200\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 1.3607 - acc: 0.5604\n",
      "Epoch 199/200\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 1.3666 - acc: 0.5607\n",
      "Epoch 200/200\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 1.3216 - acc: 0.5743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93f8d9e990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(training_examples, y_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 5s 154us/step\n",
      "[1.4454273156642914, 0.55000000000000004]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model_1.evaluate(training_examples, y_train, batch_size=32)\n",
    "print loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this current network architecture gives us a 55% accuracy on the test set-- a major improvement from the single digit percentages we were getting with scikit-learn. This may be a function of having more control over the structure of a kera's model as opposed to a scikit-learn model. This also a major improvement over the 7% accuracy we got on the test set with less training data, and a less complex network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f936d671c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe performance on via some plots. We will look at the performance of our original model first. This model has 4 hidden units, each with 100 hidden layers. It is being trained on 9000 examples, and validated against 1000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = total_scaled[:10000]\n",
    "#training_examples = random.sample(total_array, 10)\n",
    "labels = total_labels[:10000]\n",
    "y_labels = keras.utils.to_categorical(labels, num_classes=2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 5s 581us/step - loss: 6.2548 - acc: 0.0634 - val_loss: 4.2501 - val_acc: 0.0900\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 5s 533us/step - loss: 3.5748 - acc: 0.0654 - val_loss: 3.5275 - val_acc: 0.0300\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 5s 565us/step - loss: 3.4671 - acc: 0.0712 - val_loss: 3.6483 - val_acc: 0.0670\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 5s 558us/step - loss: 3.4301 - acc: 0.0766 - val_loss: 3.4098 - val_acc: 0.0400\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 5s 549us/step - loss: 3.4021 - acc: 0.0734 - val_loss: 3.3899 - val_acc: 0.1040\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 5s 559us/step - loss: 3.3832 - acc: 0.0752 - val_loss: 3.5745 - val_acc: 0.0300\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 5s 556us/step - loss: 3.3551 - acc: 0.0806 - val_loss: 3.2978 - val_acc: 0.1040\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 5s 564us/step - loss: 3.3361 - acc: 0.0824 - val_loss: 3.5335 - val_acc: 0.0660\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 5s 568us/step - loss: 3.3200 - acc: 0.0847 - val_loss: 3.2977 - val_acc: 0.0750\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 3.3028 - acc: 0.0891 - val_loss: 3.2212 - val_acc: 0.0930\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 5s 589us/step - loss: 3.2763 - acc: 0.0930 - val_loss: 3.2302 - val_acc: 0.0610\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 6s 644us/step - loss: 3.2556 - acc: 0.0953 - val_loss: 3.2469 - val_acc: 0.0710\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 5s 595us/step - loss: 3.2376 - acc: 0.1021 - val_loss: 3.2815 - val_acc: 0.0590\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 6s 653us/step - loss: 3.2169 - acc: 0.1014 - val_loss: 3.2468 - val_acc: 0.0740\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 6s 673us/step - loss: 3.1968 - acc: 0.1058 - val_loss: 3.1845 - val_acc: 0.1030\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 5s 600us/step - loss: 3.1723 - acc: 0.1110 - val_loss: 3.2100 - val_acc: 0.1090\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 5s 590us/step - loss: 3.1521 - acc: 0.1157 - val_loss: 3.2090 - val_acc: 0.0950\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 5s 596us/step - loss: 3.1323 - acc: 0.1158 - val_loss: 3.2940 - val_acc: 0.1050\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 5s 609us/step - loss: 3.1114 - acc: 0.1209 - val_loss: 3.1506 - val_acc: 0.1110\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 5s 608us/step - loss: 3.0898 - acc: 0.1250 - val_loss: 3.2059 - val_acc: 0.0770\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 6s 637us/step - loss: 3.0705 - acc: 0.1316 - val_loss: 3.2870 - val_acc: 0.0470\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 5s 587us/step - loss: 3.0481 - acc: 0.1352 - val_loss: 3.2770 - val_acc: 0.0780\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 5s 600us/step - loss: 3.0300 - acc: 0.1378 - val_loss: 3.2518 - val_acc: 0.0800\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 5s 602us/step - loss: 3.0111 - acc: 0.1400 - val_loss: 3.2895 - val_acc: 0.0790\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 5s 577us/step - loss: 2.9948 - acc: 0.1477 - val_loss: 3.2203 - val_acc: 0.0810\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 5s 579us/step - loss: 2.9735 - acc: 0.1510 - val_loss: 3.3166 - val_acc: 0.0850\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 5s 590us/step - loss: 2.9548 - acc: 0.1530 - val_loss: 3.3608 - val_acc: 0.0650\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 5s 596us/step - loss: 2.9354 - acc: 0.1592 - val_loss: 3.2746 - val_acc: 0.0890\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 7s 791us/step - loss: 2.9173 - acc: 0.1613 - val_loss: 3.2565 - val_acc: 0.1090\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 9s 1ms/step - loss: 2.8949 - acc: 0.1670 - val_loss: 3.2741 - val_acc: 0.1110\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 6s 660us/step - loss: 2.8779 - acc: 0.1723 - val_loss: 3.2687 - val_acc: 0.1020\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 5s 578us/step - loss: 2.8564 - acc: 0.1770 - val_loss: 3.3675 - val_acc: 0.0790\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 5s 590us/step - loss: 2.8343 - acc: 0.1812 - val_loss: 3.3000 - val_acc: 0.0850\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 5s 605us/step - loss: 2.8135 - acc: 0.1873 - val_loss: 3.3299 - val_acc: 0.1030\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 5s 545us/step - loss: 2.7966 - acc: 0.1982 - val_loss: 3.4400 - val_acc: 0.0760\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 5s 580us/step - loss: 2.7703 - acc: 0.1994 - val_loss: 3.3503 - val_acc: 0.0900\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 6s 678us/step - loss: 2.7533 - acc: 0.2017 - val_loss: 3.3211 - val_acc: 0.1030\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 7s 726us/step - loss: 2.7269 - acc: 0.2122 - val_loss: 3.4741 - val_acc: 0.0990\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 7s 778us/step - loss: 2.7045 - acc: 0.2196 - val_loss: 3.5327 - val_acc: 0.0910\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 6s 669us/step - loss: 2.6795 - acc: 0.2247 - val_loss: 3.4037 - val_acc: 0.0900\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 2.6582 - acc: 0.2266 - val_loss: 3.4803 - val_acc: 0.1040\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 6s 714us/step - loss: 2.6331 - acc: 0.2394 - val_loss: 3.4853 - val_acc: 0.0780\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 7s 743us/step - loss: 2.6089 - acc: 0.2426 - val_loss: 3.5449 - val_acc: 0.0880\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 6s 654us/step - loss: 2.5821 - acc: 0.2527 - val_loss: 3.5218 - val_acc: 0.0900\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 6s 651us/step - loss: 2.5648 - acc: 0.2544 - val_loss: 3.6025 - val_acc: 0.0930\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 5s 590us/step - loss: 2.5345 - acc: 0.2647 - val_loss: 3.6258 - val_acc: 0.0880\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 5s 583us/step - loss: 2.5120 - acc: 0.2718 - val_loss: 3.5815 - val_acc: 0.0890\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 5s 597us/step - loss: 2.4828 - acc: 0.2740 - val_loss: 3.7032 - val_acc: 0.0830\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 5s 581us/step - loss: 2.4579 - acc: 0.2847 - val_loss: 3.5958 - val_acc: 0.0920\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 5s 584us/step - loss: 2.4300 - acc: 0.2884 - val_loss: 3.7844 - val_acc: 0.0830\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 5s 583us/step - loss: 2.4066 - acc: 0.3016 - val_loss: 3.7929 - val_acc: 0.0800\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 5s 584us/step - loss: 2.3763 - acc: 0.3039 - val_loss: 3.8741 - val_acc: 0.0830\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 2.3542 - acc: 0.3137 - val_loss: 3.8544 - val_acc: 0.0730\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 5s 608us/step - loss: 2.3355 - acc: 0.3123 - val_loss: 4.1487 - val_acc: 0.0900\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 2.3010 - acc: 0.3242 - val_loss: 4.0950 - val_acc: 0.0620\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 5s 579us/step - loss: 2.2777 - acc: 0.3384 - val_loss: 4.0173 - val_acc: 0.0970\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 5s 579us/step - loss: 2.2586 - acc: 0.3399 - val_loss: 3.9545 - val_acc: 0.0870\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 2.2258 - acc: 0.3497 - val_loss: 4.0794 - val_acc: 0.0780\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 5s 524us/step - loss: 2.2006 - acc: 0.3547 - val_loss: 4.1517 - val_acc: 0.0760\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 5s 578us/step - loss: 2.1750 - acc: 0.3567 - val_loss: 4.2724 - val_acc: 0.0940\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 4s 483us/step - loss: 2.1564 - acc: 0.3649 - val_loss: 4.1647 - val_acc: 0.0830\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 5s 548us/step - loss: 2.1343 - acc: 0.3690 - val_loss: 4.1808 - val_acc: 0.0690\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 5s 515us/step - loss: 2.1012 - acc: 0.3776 - val_loss: 4.3792 - val_acc: 0.0800\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 5s 516us/step - loss: 2.0770 - acc: 0.3904 - val_loss: 4.4149 - val_acc: 0.0730\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 4s 497us/step - loss: 2.0515 - acc: 0.3957 - val_loss: 4.7039 - val_acc: 0.0770\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 5s 505us/step - loss: 2.0352 - acc: 0.4020 - val_loss: 4.3833 - val_acc: 0.1030\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 4s 453us/step - loss: 2.0113 - acc: 0.4042 - val_loss: 4.5047 - val_acc: 0.0810\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 4s 484us/step - loss: 1.9823 - acc: 0.4078 - val_loss: 4.7383 - val_acc: 0.0800\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 5s 525us/step - loss: 1.9651 - acc: 0.4164 - val_loss: 4.6302 - val_acc: 0.0790\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 4s 456us/step - loss: 1.9332 - acc: 0.4318 - val_loss: 4.6933 - val_acc: 0.0870\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 4s 467us/step - loss: 1.9203 - acc: 0.4268 - val_loss: 4.7185 - val_acc: 0.0850\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 4s 470us/step - loss: 1.8903 - acc: 0.4419 - val_loss: 4.8955 - val_acc: 0.0800\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 4s 451us/step - loss: 1.8611 - acc: 0.4460 - val_loss: 4.8991 - val_acc: 0.0990\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 4s 452us/step - loss: 1.8389 - acc: 0.4563 - val_loss: 4.9184 - val_acc: 0.0860\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 4s 482us/step - loss: 1.8213 - acc: 0.4549 - val_loss: 5.1096 - val_acc: 0.0750\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 4s 451us/step - loss: 1.8087 - acc: 0.4577 - val_loss: 4.9130 - val_acc: 0.0900\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 4s 449us/step - loss: 1.7702 - acc: 0.4687 - val_loss: 5.2751 - val_acc: 0.0940\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 5s 509us/step - loss: 1.7417 - acc: 0.4810 - val_loss: 5.1307 - val_acc: 0.0830\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 5s 588us/step - loss: 1.7167 - acc: 0.4858 - val_loss: 5.1572 - val_acc: 0.0800\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 6s 641us/step - loss: 1.6978 - acc: 0.4947 - val_loss: 5.3619 - val_acc: 0.0860\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 6s 649us/step - loss: 1.6756 - acc: 0.5018 - val_loss: 5.3407 - val_acc: 0.0770\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 7s 790us/step - loss: 1.6571 - acc: 0.5064 - val_loss: 5.3910 - val_acc: 0.0820\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 6s 676us/step - loss: 1.6443 - acc: 0.5043 - val_loss: 6.1387 - val_acc: 0.0750\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 6s 615us/step - loss: 1.6048 - acc: 0.5176 - val_loss: 5.6622 - val_acc: 0.0780\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 5s 608us/step - loss: 1.5762 - acc: 0.5247 - val_loss: 6.1318 - val_acc: 0.0560\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 5s 594us/step - loss: 1.5636 - acc: 0.5293 - val_loss: 5.7919 - val_acc: 0.0660\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 6s 613us/step - loss: 1.5321 - acc: 0.5420 - val_loss: 6.1802 - val_acc: 0.0670\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 6s 626us/step - loss: 1.5074 - acc: 0.5408 - val_loss: 5.9657 - val_acc: 0.0770\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 5s 601us/step - loss: 1.5187 - acc: 0.5439 - val_loss: 5.9653 - val_acc: 0.0790\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 6s 629us/step - loss: 1.4947 - acc: 0.5462 - val_loss: 6.0052 - val_acc: 0.0660\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 5s 600us/step - loss: 1.4433 - acc: 0.5618 - val_loss: 5.9736 - val_acc: 0.0780\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 6s 621us/step - loss: 1.4305 - acc: 0.5670 - val_loss: 6.2964 - val_acc: 0.0840\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 5s 577us/step - loss: 1.4268 - acc: 0.5660 - val_loss: 6.4746 - val_acc: 0.0700\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 5s 574us/step - loss: 1.4030 - acc: 0.5676 - val_loss: 6.6911 - val_acc: 0.0630\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 5s 577us/step - loss: 1.3793 - acc: 0.5807 - val_loss: 6.8879 - val_acc: 0.0820\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 5s 577us/step - loss: 1.3554 - acc: 0.5886 - val_loss: 6.5712 - val_acc: 0.0710\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 5s 577us/step - loss: 1.3393 - acc: 0.5910 - val_loss: 6.6277 - val_acc: 0.0600\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 5s 570us/step - loss: 1.2904 - acc: 0.6111 - val_loss: 6.4051 - val_acc: 0.0710\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 5s 569us/step - loss: 1.2812 - acc: 0.6069 - val_loss: 6.6474 - val_acc: 0.0620\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 5s 568us/step - loss: 1.2682 - acc: 0.6134 - val_loss: 7.2624 - val_acc: 0.0700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(examples, y_labels, validation_split=0.1, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc', 'loss', 'val_acc', 'val_loss']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa55eac96d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPg0Rz9DuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa55eb7ead0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa55e96e510>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa55ea6f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, it's obvious that this model underperforms because it of high variance as well as a low amount of data. In high variance settings, it is helpful to increase the amount of training data. Let's test this idea out with 30000 training examples next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
