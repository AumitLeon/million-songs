{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experimenting with Neural Network architecture\n",
    "\n",
    "Does more layers neccessarily mean better performance? In what ways can we tune our network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "examples = []\n",
    "\n",
    "# Replace filename with the path to the CSV where you have the year predictions data saved.\n",
    "filename = \"/mnt/c/Users/Aumit/Desktop/YearPredictionMSD.txt/yp.csv\"\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        content = line.split(\",\")\n",
    "        \n",
    "        labels.append(int(content[0]))\n",
    "\n",
    "        content.pop(0)\n",
    "\n",
    "        content = [float(elem) for elem in content]\n",
    "\n",
    "        # If we want a list of numpy arrays, not necessary\n",
    "        #npa = np.asarray(content, dtype=np.float64)\n",
    "\n",
    "        examples.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_array = np.array(examples)\n",
    "total_labels = np.array(labels)\n",
    "# Split training and test:\n",
    "training_examples = total_array[:100000]\n",
    "#training_examples = random.sample(total_array, 10)\n",
    "training_labels = total_labels[:100000]\n",
    "\n",
    "test_examples = total_array[-1000:]\n",
    "test_labels = total_labels[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive learning rate + smaller neural net (1 layer, 100 nodes). Using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=100, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(100), random_state=1)\n",
    "\n",
    "clf.fit(training_examples, training_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  999.]),\n",
       " array([ 2006.  ,  2006.01,  2006.02,  2006.03,  2006.04,  2006.05,\n",
       "         2006.06,  2006.07,  2006.08,  2006.09,  2006.1 ,  2006.11,\n",
       "         2006.12,  2006.13,  2006.14,  2006.15,  2006.16,  2006.17,\n",
       "         2006.18,  2006.19,  2006.2 ,  2006.21,  2006.22,  2006.23,\n",
       "         2006.24,  2006.25,  2006.26,  2006.27,  2006.28,  2006.29,\n",
       "         2006.3 ,  2006.31,  2006.32,  2006.33,  2006.34,  2006.35,\n",
       "         2006.36,  2006.37,  2006.38,  2006.39,  2006.4 ,  2006.41,\n",
       "         2006.42,  2006.43,  2006.44,  2006.45,  2006.46,  2006.47,\n",
       "         2006.48,  2006.49,  2006.5 ,  2006.51,  2006.52,  2006.53,\n",
       "         2006.54,  2006.55,  2006.56,  2006.57,  2006.58,  2006.59,\n",
       "         2006.6 ,  2006.61,  2006.62,  2006.63,  2006.64,  2006.65,\n",
       "         2006.66,  2006.67,  2006.68,  2006.69,  2006.7 ,  2006.71,\n",
       "         2006.72,  2006.73,  2006.74,  2006.75,  2006.76,  2006.77,\n",
       "         2006.78,  2006.79,  2006.8 ,  2006.81,  2006.82,  2006.83,\n",
       "         2006.84,  2006.85,  2006.86,  2006.87,  2006.88,  2006.89,\n",
       "         2006.9 ,  2006.91,  2006.92,  2006.93,  2006.94,  2006.95,\n",
       "         2006.96,  2006.97,  2006.98,  2006.99,  2007.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgAkqVMGgCR1ygCQpE79L4Z2Om1t9+DAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3a502ed50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred, bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about 2 small layers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(10, 10), random_state=1)\n",
    "\n",
    "clf.fit(training_examples, training_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,  1000.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.]),\n",
       " array([ 2006.5 ,  2006.51,  2006.52,  2006.53,  2006.54,  2006.55,\n",
       "         2006.56,  2006.57,  2006.58,  2006.59,  2006.6 ,  2006.61,\n",
       "         2006.62,  2006.63,  2006.64,  2006.65,  2006.66,  2006.67,\n",
       "         2006.68,  2006.69,  2006.7 ,  2006.71,  2006.72,  2006.73,\n",
       "         2006.74,  2006.75,  2006.76,  2006.77,  2006.78,  2006.79,\n",
       "         2006.8 ,  2006.81,  2006.82,  2006.83,  2006.84,  2006.85,\n",
       "         2006.86,  2006.87,  2006.88,  2006.89,  2006.9 ,  2006.91,\n",
       "         2006.92,  2006.93,  2006.94,  2006.95,  2006.96,  2006.97,\n",
       "         2006.98,  2006.99,  2007.  ,  2007.01,  2007.02,  2007.03,\n",
       "         2007.04,  2007.05,  2007.06,  2007.07,  2007.08,  2007.09,\n",
       "         2007.1 ,  2007.11,  2007.12,  2007.13,  2007.14,  2007.15,\n",
       "         2007.16,  2007.17,  2007.18,  2007.19,  2007.2 ,  2007.21,\n",
       "         2007.22,  2007.23,  2007.24,  2007.25,  2007.26,  2007.27,\n",
       "         2007.28,  2007.29,  2007.3 ,  2007.31,  2007.32,  2007.33,\n",
       "         2007.34,  2007.35,  2007.36,  2007.37,  2007.38,  2007.39,\n",
       "         2007.4 ,  2007.41,  2007.42,  2007.43,  2007.44,  2007.45,\n",
       "         2007.46,  2007.47,  2007.48,  2007.49,  2007.5 ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3a4f31dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some next steps: \n",
    "* Consider shuffling and picking random samples for training and test sets as opposed to just selecting the first 100000 for our training data. \n",
    "* Figure out how many hidden layers/nodes we should have: ftp://ftp.sas.com/pub/neural/FAQ3.html#A_hu\n",
    "* Confirm that the neural net is performing the way we think it should be performing with psedo input. If the the network fails on fake input, then we know that there is an issue somewhere in our pipelne. https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
